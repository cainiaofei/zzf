\chapter{相关工作}

\section{需求可追踪性}
需求追踪是指跟踪一个需求使用期限的全过程，需求追踪包括编制每个需求同系统元素之间的联系文档，这些元素包括其他类型的需求，体系结构，其他设计部件，源代码模块，测试，帮助文件等。需求跟踪为我们提供了由需求到产品实现整个过程范围的明确查阅的能力。
Gotel等人对需求追踪问题进行了一系列的实际调查和分析，并给出了需求追踪的定义：在软件整个生命周期中，对某一特定需求从前后两个方向描述和追踪的能力。如图~\ref{F:requirement_traceability}所示需求追踪分成两个方向，前向追踪是从书写文档形式的需求追踪到需求来源，后向追踪是从需求文档软件发布过程中的各种制品（例如测试集合、代码、设计文档等）~\cite{gotel1994analysis}。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.3\textwidth]{./figures/related_work/requirement_traceability.pdf}
    \caption{需求追踪}
    \label{F:requirement_traceability}
\end{figure}



需求到其它任何软件制品的追踪关系都可以用一个二维矩阵来描述。表~\ref{Traceability-Matrix}描述了需求到代码的可追踪关系。
\begin{table}[htbp]
\centering
\caption{需求追踪矩阵}
\label{Traceability-Matrix}
\begin{tabular}{@{}cccccc@{}}
\toprule
      & $Requirement_{1}$ & $Requirement_{2}$ & $Requirement_{3}$ & ... & $Requirement_{n}$ \\ \midrule
$Code_{1}$ & X            &              &              &     &              \\
$Code_{2}$ &              & X            &              &     &              \\
$Code_{3}$ & X            &              &              &     & X            \\
$Code_{4}$ &              &              & X            &     & X            \\
...   &              &              &              &     &              \\
$Code_{n}$ &              & X            &              &     &              \\ \bottomrule
\end{tabular}
\end{table}
其中行为代码项，列为需求项。每一行代表该代码项与哪些需求有关，每一列表示该需求由哪些代码项来完成。‘X’表示代码项和需求项之间存在实现关系（追踪关系）。在实际的软件生成过程中，代码的粒度通常是类或者函数，需求的粒度可以是用例（~Use ~Case）或
声明（~Requirement ~Statement）。


\section{信息检索技术}
\label{sec:information_retrieve_technique}
信息检索技术是软件可追踪生成领域中研究最多、应用最广泛的分析方法。该方法通过计算查询文档和目标文档之间的文本相似度，进而检索出与查询文档相关的目标文档交由用户判断。一方面该方法具有人工参与少、自动化程度高、易于实现等优点；另一方面该方法严重依赖文本质量，普遍存在单词失配问题。本小节主要介绍VSM、LSI 和JS
~\cite{abadi2008traceability}三种常用的信息检索模型。VSM模型将对文本内容的处理简化为向量空间中的向量运算，用向量来表示查询和目标文档，目标文档根据向量之间的余弦距离排序；LSI是一个简单实用的主题模型，基于奇异值分解（SVD）的方法得到文本的主题，克服了VSM模型中存在的近义词和多义词问题。JS属于概率模型，估计文档和查询相关的概率。

%\subsection{VSM}

VSM（Vector Space Model）在信息检索和搜索引擎中应用非常广泛，也是一种自然语言处理中常用的模型。该模型用向量来表示查询和目标文档，将对文本内容的处理转化为向量空间种的向量运算。查询和目标文档中的每个此项用向量中的一个维度来描述。

如果文档中没有出现某个词项，此时该查询向量与该词项对应维度的值就是零。这个值用来刻画词项在文档中的权重。有很多计算词项权重的方法，其中应用比较广泛的计算方法为TF-IDF，它有词项的局部权重和全局权重两部分组成。TF（term frequency）表示当前文档中的某个词项在当前文档中的出现频率。直觉上，某一词项在文档中出现的次数越多权重应该越大，但是这里有个缺陷在于，不同文档长度不同。长文档包含的词项比较多。因此我们用某词项出现的次数除以其所在文档的总词项数来表示该词项的频率。TF计算公式如下：
\begin{align}
    tf_{i,j}=\dfrac {n_{i,j}} {\sum _{k}n_{k,j}}
\end{align}

其中$n_{i,j}$表示词项$t_{i}$在文档$d_{j}$中出现的次数。分母表示文档$d_{j}$中出现的总词项数。结果$tf_{i,j}$表示词项$t_{i}$ 在文档$d_{j}$中出现的频率。

对于词项的全局权重，如果一个词项普遍存在于各个文档中。极端条件下所有文档中都有该词项，则该词项没办法用来区分不同的文档，即其权重比较低。如果只有很少的文档出现了某词项，那么通过该词项很容易区分开出现过它的文档和未出现它的文档，所以此时应该赋予该词项较高的权重。IDF计算公式如下：
\begin{align}
     idf_{i}=\log \dfrac {\left| D\right| } {\{\left| j:t_{i}\in d_{j}\right| \}}
\end{align}
其中$\left| D\right|$ 表示总的文档个数，分母表示出现词项$t_{i}$ 的文档数目

TF-IDF值由词项的局部权重值和全局权重值综合决定，其计算公式如下：
\begin{align}
    tfidf_{i,j}=tf_{i,j} \times idf_{i}
\end{align}
即词项的本地权重值乘以词项的全局权重值。

相似度计算的合理性在于，存在较多共享词项的两个文档，往往是在描述同样的信息。描述不同信息的文档往往使用不同的词项。
由于向量空间模型将目标文档与查询文档用高维空间中的一个向量来表示，这两个文档之间的文本之间的相似度可以用这两个空间向量的相似度来表示，给定查询向量$q$, 目标文档向量$d$, 向量长度均为$n$, 那么其余弦相似度定义为：
\begin{align}
    sim(d_{j},q)=\dfrac {\sum _{i=1}^{n}w_{i,j} \times w_{i,q}} {\sqrt {\sum _{i=1}^{n}w_{i,j}^{2}} \ \times \sqrt {\sum _{i=1}^{n}w_{i,q}^{2}}}
  \end{align}
其中，$w$表示对应文档中由TF-IDF计算而来的词项权重。

LSI（Latent semantic indexing，潜在语义索引）~\cite{deerwester1990indexing,dumais1991improving} VSM模型中并没有考虑词项之间的关联性。例如，对于分别出现了“automobile” 和“car” 词项的两个文档，虽然这两个词项是同义词均表示“汽车”。但是在VSM 模型下，两个文本之间的相似度不会因为有大量同义词而变大。LSI模型能够捕获词项之间的相关性，如果两个词项之间具有很强的相关性，那么当一个词项出现时，往往意味着另一个词项也会出现（同义词）；反之，如果查询文档或者目标文档中的某个词项和其它词项的相关性都不大，那么这个词项很可能表示的是另一个意思（一词多义，比如Apple 在不同语境下可能是水果也可能是指手机）。LSI采用奇异值矩阵分解（SVD）
~\cite{salton1986introduction}对VSM模型下的词项-文档矩阵（Term-by-Document）进行分解。奇异值矩阵分解可以看作是从单词-文档矩阵中发现不相关的索引变量（因子），将原来的数据映射到语义空间内。在词项-文档矩阵中不相似的两个文档，可能在语义空间内比较相似。
SVD背后的形式化比较复杂，详细内容可参考文献 ~\cite{salton1986introduction}。简单来说，奇异值分解是对矩阵进行分解的一种方法。它能够将一个大矩阵表示为三个小矩阵的乘积，并且与特征分解不同，奇异值分解不要求被分解矩阵为方阵。假设我们的矩阵A 是一个$m$ $\times$ $m$的矩阵，其中的元素全部属于域K，也就是实数域或复数域。如此则存在一个分解使得：
\begin{align}
    A = U \Sigma V^T
\end{align}
其中U是$m$ $\times$ $m$阶酉矩阵，$\Sigma$是半正定$m\times n$ 阶对角矩阵，而$V^T$即$V$的共轭转置，是$n\times n$阶酉矩阵。这样的分解就称做M的奇异值分解。$\Sigma$对角线上的元素即为矩阵A的奇异值。
常见的做法是对奇异值自大到小进行排序，这样$\Sigma$可以由矩阵A唯一确定。可以直观的理解为，矩阵U的列向量（左奇异向量）组成一套对矩阵A 的正交“输入”或“分析”的基向量。这些向量是$AA^T$的特征向量。矩阵V的列向量（右奇异向量）组成一套对矩阵A 的“正交”输出的基向量。这些向量是$M^{T}M$ 的特征向量。$\Sigma$ 对角线上的元素是奇异值，可视为是输入与输出间进行的标量的“膨胀控制”。这些是$MM^T$及$M^{T}M$ 的奇异值，并与U和V的列向量相对应。
对奇异值自大到小排序，取前k个$A$的奇异值利用$X_{k}$ $=$ $U_{k}$$\Sigma_{k}$$V_{k}^T$构造$X$的秩－k近似矩阵，重建的矩阵是一个最小二乘法拟合。其中$U$和$V$ 的列向量正交，即$U^TU$ $=$ $V^TV$ $=$ $I_{r}$，其中$r$是原矩阵$X$的秩。
$X_{k}$为原矩阵$X$的k维最佳近似矩阵，由k个最大的奇异三元组构造而成。

LSI通过奇异值矩阵分解将原始词项文档矩阵降维，投影到一个缩小的空间中，以消除词语使用中的“噪声”。在LSI模型中，检索是基于文档的语义内容而不是其词汇内容。为了取得较好的检索结果，选择合适的K值很重要。理想情况下，我们选择一个K值能包含数据中所有的主题模型，同时能过滤掉所有噪音。实际中，选择最优K值的方法还是一个公开问题~\cite{Scott1990LSI}。当前K值的选择通常由实验决定。降维之后的查询、文档向量通过将VSM空间的相关向量投影至LSI子空间生成，类似VSM模型，查询语句与目标文档之间的相似度即为对应向量的余弦距离。

%\subsection{JS}
JS模型（Jensen-Shannon similarity model）是一种由概率方法和假设检验技术驱动的新型信息检索技术。在概率模型中，查询语句和目标文档都被假定具有潜在的概率分布。通过对查询和目标文档对应概率分布的距离进行排序的方法，达到检索的目的。根据假设检验
~\cite{Gutman1989Gutman}的结论，将查询和目标文档看作是词项的概率分布，两者之间的差异通过JS散度来度量。公式如下：
\begin{align}
    JS(q,d) \triangleq H(\dfrac {\hat {p}_{q}+\hat {p}_{d}} {2}) - \dfrac {H(\hat {p}_{q})+H(\hat{p}_{d})} {2}
\end{align}
\begin{align}
    H(p) \triangleq \sum _{w\in W}h(p(w)),\ h(x) \triangleq -x\log x
\end{align}

其中$H(p)$代表概率分布$p$的熵，$\hat{p}_{q}$和$\hat{p}_{d}$ 分别为查询语句和目标文档的概率分布。我们注意到，根据定义当x 为0时，h(0)恒等于0。因此我们定义查询语句和目标文档之间的相似度为1-JS(q,d)。

\section{增强策略}
针对信息检索方法的单词失配问题，领域内提出了一些增强策略。当前主流的两种增强策略为：结合代码依赖信息和结合用户反馈信息（user feedback）。

\subsection{代码依赖}
在基于信息检索方法对需求到代码的可追踪性生成过程中，往往因为词汇失配问题（需求往往使用领域相关词汇，代码往往使用缩写，同义词，专业术语等）使得生成追踪列表的精度（准确率，完全率）有限。本小节主要介绍使用代码依赖信息对信息检索得到的候选追踪线索列表进行优化的一些相关工作。

对于基于信息检索方法生成的候选追踪线索列表，~\cite{mcmillan2009combining}利用代码依赖关系对列表重排序。我们的之前工作
~\cite{kuang2015can}
对代码依赖细分为直接代码依赖（类之间的继承、使用和方法之间的调用）、数据依赖（类之间的数据共享），直接依赖表达的是软件的控制流，数据依赖表达的是软件的数据流。该工作表明对于需求到代码的可追踪性生成，代码元素的直接依赖和数据依赖起到互补的作用，两者相结合要比单独使用其中一种取得更好的效果。后续工作~\cite{Kuang2017closeness} 对代码依赖之间的紧密度进行了量化。对于代码之间的代码依赖，该工作认为两个类交互越多并且其它类交互的越少，则这两个类之间的代码依赖紧密度越高。
该工作通过引入代码紧密度分析，对基于信息检索方法生成的候选追踪列表进行了优化。具体来说，该方法首先利用信息检索方法生成候选追踪线索排序表（~\cite{cleland2005utilizing}位于列表顶部的候选线索大概率是具备相关性的）。接下来，根据其它代码元素与列表顶部对应代码元素之间的代码依赖紧密度值，调整它们对应候选追踪线索的相似度值，进而优化它们在排序表的位置。


\subsection{用户反馈}
如前文~\ref{sec:information_retrieve_technique}所述，信息检索方法严重依赖软件制品的语料质量，用户需要自上而下扫描信息检索生成的候选追踪线索列表，并验证追踪线索的相关性。
近期大量工作提出根据用户对当前候选线索相关性的验证结果来优化余下的候选线索追踪列表排序~\cite{hayes2006advancing,Lucia2006Incremental,Panichella2015Adaptive,Zhang2012The} 。
hayes等人的工作中，假设$q$是一个查询向量，集合$D_{q}$ 是用信息检索方法通过查询$q$ 得到的文档集合。假设文档集合$D$ 由两个子集合$D_{r}$与$D_{irr}$组成，其中$D_{r}$集合中的文档是用户判断结果为与查询语句相关的文档，$D_{irr}$ 为与查询语句无关的文档，它们所包含的文档个数分别为$R$ 和$S$。很明显$D_{r}$集合和$D_{irr}$集合没有交集，并且
由于这两个集合里面都是用户判断过的文档，所以它们的并集也未必是$D_{q}$，因为可能有些文档用户还没判断。
使用标准Rochio~\cite{Yates1999IR} 反馈处理算法，在下一轮迭代中修改查询向量各词项的权重~\cite{hayes2006advancing}，公式如下：
\begin{align}
    q_{new} = \alpha \cdot q +(\dfrac {\beta}{R} \sum_{d_{j} \in D_{r}}d_{j}) - (\dfrac{\gamma}{S}\sum_{d_{k}\in D_{irr}}d_{k} )
\end{align}
直觉上，通过将相关文档中出现的词项加到查询语句中可以使得查询语句与其它相关文档共享更多的词项，从而提高完全率；削弱查询语句中在不相关文档中出现词项的权重，可以使得查询语句远离不相关文档，进而减小犯错的概率，增加准确率。上式子中，可以通过调整参数 $\alpha$ 、 $\beta$ 、 $\gamma$ 来改变原始查询语句、相关文档和不相关文档中对生成新查询语句的贡献程度。新查询语句生成之后，重新使用信息检索方法并对检索得到的相关文档按相似度排序，重复以上过程，直到用户取得满意的结果。然而后续工作
发现在做需求追踪时用Rochio反馈处理方法只有在前几次迭代中会提高准确率和完全率~\cite{Lingjun2009Refinement}。
Lucia等人的工作表明标准Rochio反馈处理方法对信息检索方法生成排序表的优化并不明显，尤其是当查询语句和文档语料质量比较好，使得信息检索结果的质量比较高时，Rochio反馈处理方法对信息检索的结果几乎起不到任何优化作用，对于其它软件制品之间做可追踪性（例如用例和UML图之间）使用Rochio 方法不仅不能提升排序表的效果反而可能会让效果并得更差~\cite{Lucia2006Incremental}。
Zhang等人对不同查询语句进行了分类，与~\cite{hayes2006advancing} 使用固定的参数 $\alpha$ 、 $\beta$ 、 $\gamma$ 不同， 根据查询语句所属类别采用不同的参数并取得一定的效果~\cite{Zhang2012The}。使用Rocchio算法利用用户反馈（user feedback）信息提高对查询语句的检索效果要基于两个前提条件~\cite{Manning2008Introduction}：
\begin{enumerate}
   \item Rocchio算法基于的假设是：查询语句与目标文档相比，词项比较少。
   \item 与查询语句相关的文档之间相似度比较高，假如对查询和文档进行分析，查询和相关文档应该能聚到同一个类中（聚类假设）。
\end{enumerate}
Panichella等人认为在需求追踪环境下以上两个前提假设均不成立，有些查询语句（需求的文本文档）词项比目标文档（代码文档）要多~\cite{Panichella2015Adaptive}。
%因此像之前工作~\cite{hayes2006advancing,Lingjun2009Refinement,Lucia2006Incremental} 那样不考虑前提条件是否满足直接使用用户反馈。
并且，聚类假设也不成立，根据相关文献~\cite{Lawrie2010Normalizing,Lawrie2011identifiers}，需求实体和代码实体往往使用不同的词典，需求实体往往使用问题领域词项，代码实体则使用技术领域词项和一些缩写同义词等。综上
~\cite{Panichella2015Adaptive}提出一种方法，只有查询语句的词项小于等于相关文档，并且用户判断的文档中与查询语句相关的文档比不相关的文档多时才对用户反馈使用Rocchio算法，该方法取得一定效果。
%详见算法~\ref{alg:ARF}~：

与上述工作从通过用户对候选线索的反馈结果优化排序不同，~\cite{Wang2018Term}基于n-gram模型对查询语句进行分析，对不同的词项采取不同的权重调整策略（增大，减小，不变）。~\cite{Antoniol2000Modelling,Penta2002RAD}先让用户判断一部分候选追踪线索，作为方法的训练集。具体来~ 说，~\cite{Antoniol2000Modelling}使用一组被判断过的追踪线索（训练集）作为贝叶斯分类器的输入，通过对测试集进行学习来提高基于概率模型的信息检索方法的准确率。~\cite{Guo2017deep}提出了一种使用嵌入词项和RNN技术的神经网络结构来生成软件制品之间相关性的方法。与基于信息检索的方法类似，该方法也会分析查询语句和目标文档的文本相似度，将用户已经判断过的追踪线索作为训练集作为方法的输入。相对于传统的基于VSM 和LSI模型的信息检索方法，~\cite{Guo2017deep} 方法得到的结果分别提高了41\%和32\%。但是该方法需要45\%的测试集和10\%的用户已经判断的追踪线索对通过训练集得到的分类模型进行优化。即用户需要判断所以候选追踪线索的55\%。 这在实践中会耗费大量的用户精力。

~\cite{panichella2013and} 认为对于使用代码结构信息来调整候选追踪列表的方法~\cite{mcmillan2009combining}，其最好的效果和信息检索方法得到的候选追踪线索排序表有很大关系。~\cite{mcmillan2009combining}当某个文档和查询语句相似度比较大时，此时增大与文档存在结构依赖的其他文档与查询语句的相似度。但是在文档文本质量比较差的情况下。如果与查询语句相似度比较大的文档本身和查询语句就没有相关性，此时利用代码依赖就会将错误扩大，对信息检索方法得到的候选追踪线索排序表造成污染。~\cite{panichella2013and}提出，每次将排序表顶端的追踪线索交由用户验证，只有用户判断该追踪线索相关时才提高与该追踪线索具有代码依赖的其它追踪线索的相似度值。与~\cite{hayes2006advancing,Lucia2006Incremental,Panichella2015Adaptive} 不同，~\cite{panichella2013and}不会改变词项的权重，因此不需要每次重新计算相似度。该方法相似步骤见算法~\ref{alg:UD_CSTI}
\begin{algorithm}[!htbp]
\caption{User-Driven Combination of Structural and Textual Information ― UD-CSTI}
\label{alg:UD_CSTI}
    \While {not (stopping criterion)}
    {
      Get the link ($s$, $c_{j}$) on top of List\\
      The user classifies ($s$, $c_{j}$)\\
       \If {$s$, $c_{j}$ is correct}
       {
          \ForAll {$c_{t} \in C$} {
            \If {$(c_{j}, c_{t}) \in E$} {
              Sim($s$, $c_{t}$) $\leftarrow$ Sim($s$, $c_{t}$) + $\delta$ $\times$ Sim($s$, $c_{t}$)
            }
          }
       }
      Reorder List\\
      Hide links already classified
    }
\end{algorithm}

其中$\delta$为相似度奖励系数，用来调节相关追踪线索相似度的变化程度。对于不同的追踪列表，该变量应该取不同的值，考虑到当候选列表的值分布比较集中时，该值稍微大一点就会使得相关候选追踪线索相似度值调整之后的排序会发生很大的变化；当候选列表的值分布比较发散是，该值过小可能使得相关线索虽然小相似度值增大，但是对其再排序表的位置确影响不大。该方法提出自适应的$\delta$。
\begin{align}
    \delta = median\{v_{i},...,v_{n}\}
\end{align}
其中$v_{i}=(max_{i}-min_{i})/2$，$v_{i}$与第$i$个查询文档对应目标文档的相似度最大值和最小值。


\section{软件可追踪数据集构造}
Cleland-Huang等人提出需求追踪领域面临的一个挑战是，当研究者想验证自己方法有效性时，需要搭建基线方法的实验运行环境，这个过程会耗费大量精力，并且有些实验用到的标准可追踪数据集往往不公开~\cite{Cleland-Huang2011challenges}。
Charrada等人认为用于方法验证的可追踪性数据集比较少，研究者为了验证自己方法有效性往往需要自己做数据集，这个过程会消耗用户大量时间。Charrada 等人公布了一个针对一个灌溉系统的数据集，包括了改系统各种软件制品之间的追踪关系。同时通过用同样的方法对该数据集和领域内常用的数据集进行处理，比较它们precision/recall图像的相似性，验证该数据集的有效性~\cite{Charrada2011Benchmark}。Chen等人提出一个概率模型，以帮助用户建立可靠的数据集并公开了他们采用这种方法构造的JDK1.5 的数据集~\cite{Chen2013Robust}。

上述方法均为纯人工构造数据集的方法，由代码托管的开源软件通常采用一些任务管理工具（例如issue-tracking）来维护软件的行为信息
~\cite{Rath2017IlmSeven}。
用户会在需求管理系统提交软件行为变更申请（issue），该issue可能软件相关的bug或者新的需求（new feature）等类型。研发人员会对用户所提交的issue 进行评审以决定是拒绝该issue还是接受该issue。 如果是后者，接下来会完成与issue相关的代码
（可能是完成某个需求也可能是修复某个bug）。然后用户会将更改的代码提交到代码托管平台。
很自然的这里issue 和提交的代码就形成了需求到代码的追踪关系。~\cite{Shi2017linguistic} 对需求管理系统中的new feature文本进做了进一步分类，使得我们对new feature 能有更好的利用。

\section{本章小结}
本章介绍了需求到代码可追踪生成的相关技术，并分析了现有方法的不足。同时本章介绍了在需求可追踪性、追踪矩阵构造等相关领域，已有工作如何结合代码结构信息和用户反馈信息以提高原有方法的精度。
