\chapter{相关工作}

\section{需求可追踪性}
需求跟踪是指跟踪一个需求使用期限的全过程，需求跟踪包括编制每个需求同系统元素之间的联系文档，这些元素包括其他类型的需求，体系结构，其他设计部件，源代码模块，测试，帮助文件等。需求跟踪为我们提供了由需求到产品实现整个过程范围的明确查阅的能力。
Gotel对需求追踪问题进行了一系列的实际调查和分析，并给出了需求追踪的定义：在软件整个生命周期中，对某一特定需求从前后两个方向描述和追踪的能力。需求追踪分成两个方向，前向追踪是从书写文档形式的需求追踪到需求来源，后向追踪是从需求文档软件发布过程中的各种制品（例如测试集合、代码、设计文档等）~\cite{gotel1994analysis}。

需求到其它任何软件制品的追踪关系都可以用一个二维矩阵来描述。例如，表\ref{Traceability-Matrix}描述了需求到代码的可追踪关系。
\begin{table}[]
\centering
\caption{需求追踪矩阵（需求到代码）}
\label{Traceability-Matrix}
\begin{tabular}{@{}cccccc@{}}
\toprule
      & $Requirement_{1}$ & $Requirement_{2}$ & $Requirement_{3}$ & ... & $Requirement_{n}$ \\ \midrule
$Code_{1}$ & X            &              &              &     &              \\
$Code_{2}$ &              & X            &              &     &              \\
$Code_{3}$ & X            &              &              &     & X            \\
$Code_{4}$ &              &              & X            &     & X            \\
...   &              &              &              &     &              \\
$Code_{n}$ &              & X            &              &     &              \\ \bottomrule
\end{tabular}
\end{table}
行为代码项，列为需求项。每一行代表该代码项与哪些需求有关，每一列表示该需求由哪些代码项来完成。‘X’表示代码项和需求项之间存在实现关系（追踪关系）。在实际的软件生成过程中，代码的粒度通常是类或者函数，需求的粒度可以是用例（Use Case）或
声明（requirement Statement）。


\section{信息检索技术}
信息检索技术是软件可追踪生成领域中研究最多、应用最广泛的分析方法。该方法通过计算查询文档和目标文档之间的文本相似度，进而检索出与查询文档相关的目标文档，该方法具有人工参与少、自动化程度高、易于实现等特点。本小节主要介绍VSM、LSI和JS
~\cite{abadi2008traceability}三种常用的信息检索模型。VSM模型将对文本内容的处理简化为向量空间中的向量运算，用向量来表示查询和目标文档，目标文档根据向量之间的余弦距离排序；LSI是一个简单实用的主题模型，基于奇异值分解（SVD）的方法得到文本的主题，克服了VSM模型中存在的近义词和多义词问题。JS属于概率模型，估计文档和查询相关的概率。

\subsection{VSM}
VSM（Vector Space Model）在信息检索和搜索引擎中应用非常广泛，也是一种自然语言处理中常用的模型。该模型用向量来表示查询和目标文档，将对文本内容的处理转化为向量空间种的向量运算。查询和目标文档中的每个此项用向量中的一个维度来描述。

如果文档中没有出现某个词项，此时该查询向量与该词项对应维度的值就是零。这个值用来刻画词项在文档中的权重。有很多计算词项权重的方法，其中应用比较广泛的计算方法为TF-IDF，它有词项的局部权重和全局权重两部分组成。TF（term frequency）表示当前文档中的某个词项在当前文档中的出现频率。直觉上，某一词项在文档中出现的次数越多权重应该越大，但是这里有个缺陷在于，不同文档长度不同。长文档包含的词项比较多。因此我们用某词项出现的次数除以其所在文档的总词项数来表示该词项的频率。TF计算公式如下：
\begin{align}
    tf_{i,j}=\dfrac {n_{i,j}} {\sum _{k}n_{k,j}}
\end{align}

其中$n_{i,j}$表示词项$t_{i}$在文档$d_{j}$中出现的次数。分母表示文档$d_{j}$中出现的总词项数。结果$tf_{i,j}$表示词项$t_{i}$ 在文档$d_{j}$中出现的频率。

对于词项的全局权重，如果一个词项普遍存在于各个文档中。极端条件下所有文档中都有该词项，则该词项没办法用来区分不同的文档，即其权重比较低。如果只有很少的文档出现了某词项，那么通过该词项很容易区分开出现过它的文档和未出现它的文档，所以此时应该赋予该词项较高的权重。IDF计算公式如下：
\begin{align}
     idf_{i}=\log \dfrac {\left| D\right| } {\{\left| j:t_{i}\in d_{j}\right| \}}
\end{align}
其中$\left| D\right|$ 表示总的文档个数，分母表示出现词项$t_{i}$ 的文档数目

TF-IDF值由词项的局部权重值和全局权重值综合决定，其计算公式如下：
\begin{align}
    tfidf_{i,j}=tf_{i,j} \times idf_{i}
\end{align}
即词项的本地权重值乘以词项的全局权重值。

相似度计算的合理性在于，存在较多共享词项的两个文档，往往是在描述同样的信息。描述不同信息的文档往往使用不同的词项。
由于向量空间模型将目标文档与查询文档用高维空间中的一个向量来表示，这两个文档之间的文本之间的相似度可以用这两个空间向量的相似度来表示，给定查询向量$q$, 目标文档向量$d$, 向量长度均为$n$, 那么其余弦相似度定义为：
\begin{align}
    sim(d_{j},q)=\dfrac {\sum _{i=1}^{n}w_{i,j} \times w_{i,q}} {\sqrt {\sum _{i=1}^{n}w_{i,j}^{2}} \ \times \sqrt {\sum _{i=1}^{n}w_{i,q}^{2}}}
  \end{align}
其中，$w$表示对应文档中由TF-IDF计算而来的词项权重。

\subsection{LSI}
LSI（Latent semantic indexing，潜在语义索引）~\cite{deerwester1990indexing,dumais1991improving} VSM模型中并没有考虑词项之间的关联性。例如，对于分别出现了“automobile”和“car” 词项的两个文档，虽然这两个词项是同义词均表示“汽车”。但是在VSM 模型下，两个文本之间的相似度不会因为有大量同义词而变大。LSI模型能够捕获词项之间的相关性，如果两个词项之间具有很强的相关性，那么当一个词项出现时，往往意味着另一个词项也会出现（同义词）；反之，如果查询文档或者目标文档中的某个词项和其它词项的相关性都不大，那么这个词项很可能表示的是另一个意思（一词多义，比如Apple 在不同语境下可能是水果也可能是指手机）。LSI采用奇异值矩阵分解（SVD）
~\cite{salton1986introduction}对VSM模型下的词项-文档矩阵（Term-by-Document）进行分解。奇异值矩阵分解可以看作是从单词- 文档矩阵中发现不相关的索引变量（因子），将原来的数据映射到语义空间内。在词项-文档矩阵中不相似的两个文档，可能在语义空间内比较相似。
SVD背后的形式化比较复杂，详细内容可参考文献 ~\cite{salton1986introduction}。简单来说，奇异值分解是对矩阵进行分解的一种方法。它能够将一个大矩阵表示为三个小矩阵的乘积，并且与特征分解不同，奇异值分解不要求被分解矩阵为方阵。假设我们的矩阵A 是一个$m$ $\times$ $m$的矩阵，其中的元素全部属于域K，也就是实数域或复数域。如此则存在一个分解使得：

\begin{align}
    A = U \Sigma V^T
\end{align}


其中U是$m$ $\times$ $m$阶酉矩阵，$\Sigma$是半正定$m\times n$阶对角矩阵，而$V^T$即$V$的共轭转置，是$n\times n$阶酉矩阵。这样的分解就称做M的奇异值分解。$\Sigma$对角线上的元素即为矩阵A的奇异值。
常见的做法是对奇异值自大到小进行排序，这样$\Sigma$可以由矩阵A唯一确定。可以直观的理解为，矩阵U的列向量（左奇异向量）组成一套对矩阵A 的正交“输入”或“分析”的基向量。这些向量是$AA^T$的特征向量。矩阵V的列向量（右奇异向量）组成一套对矩阵A 的“正交”输出的基向量。这些向量是$M^{T}M$ 的特征向量。$\Sigma$ 对角线上的元素是奇异值，可视为是输入与输出间进行的标量的“膨胀控制”。这些是$MM^T$及$M^{T}M$ 的奇异值，并与U和V的列向量相对应。
对奇异值自大到小排序，取前k个$A$的奇异值利用$X_{k}$ $=$ $U_{k}$$\Sigma_{k}$$V_{k}^T$构造$X$的秩－k近似矩阵，重建的矩阵是一个最小二乘法拟合。其中$U$和$V$ 的列向量正交，即$U^TU$ $=$ $V^TV$ $=$ $I_{r}$，其中$r$是原矩阵$X$的秩。
$X_{k}$为原矩阵$X$的k维最佳近似矩阵，由k个最大的奇异三元组构造而成。

LSI通过奇异值矩阵分解将原始词项文档矩阵降维，投影到一个缩小的空间中，以消除词语使用中的“噪声”。在LSI模型中，检索是基于文档的语义内容而不是其词汇内容。为了取得较好的检索结果，选择合适的K值很重要。理想情况下，我们选择一个K值能包含数据中所有的主题模型，同时能过滤掉所有噪音。实际中，选择最优K值的方法还是一个公开问题\cite{Scott1990LSI}。当前K 值的选择通常由实验决定。降维之后的查询、文档向量通过将VSM 空间的相关向量投影至LSI 子空间生成，类似VSM模型，查询语句与目标文档之间的相似度即为对应向量的余弦距离。

\subsection{JS}
JS模型（Jensen-Shannon similarity model）是一种由概率方法和假设检验技术驱动的新型信息检索技术。在概率模型中，查询语句和目标文档都被假定具有潜在的概率分布。通过对查询和目标文档对应概率分布的距离进行排序的方法，达到检索的目的。根据假设检验
~\cite{19}的结论，将查询和目标文档看作是词项的概率分布，两者之间的差异通过JS散度来度量。公式如下：
\begin{align}
    JS(q,d) \triangleq H(\dfrac {\hat {p}_{q}+\hat {p}_{d}} {2}) - \dfrac {H(\hat {p}_{q})+H(\hat{p}_{d})} {2}
\end{align}
\begin{align}
    H(p) \triangleq \sum _{w\in W}h(p(w)),\ h(x) \triangleq -x\log x
\end{align}

其中$H(p)$代表概率分布$p$的熵，$\hat{p}_{q}$和$\hat{p}_{d}$分别为查询语句和目标文档的概率分布。我们注意到，根据定义当x为0 时，h(0) 恒等于0。因此我们定义查询语句和目标文档之间的相似度为1-JS(q,d)。


\section{结合用户反馈}
一方面鉴于信息检索方法严重依赖检索语句和目标文档的质量；另一方面信息检索生成的目标文档排序列表需要用户验证每个文档和查询语句的相关性。这是个用户交互的重复过程。~\cite{hayes2006advancing,Lucia2006Incremental,Panichella2015Adaptive,Zhang2012The} 使用用户反馈对候选追踪线索的判断信息对目标文档排序表进行优化。
~\cite{hayes2006advancing}假设$q$是一个查询向量，集合$D_{q}$是用信息检索方法通过查询$q$ 得到的文档集合。假设文档集合$D$由两个子集合$D_{r}$与$D_{irr}$组成，其中$D_{r}$集合中的文档是用户判断结果为与查询语句相关的文档，$D_{irr}$为与查询语句无关的文档，它们所包含的文档个数分别为$R$ 和$S$。很明显$D_{r}$集合和$D_{irr}$集合没有交集，并且
由于这两个集合里面都是用户判断过的文档，所以它们的并集也未必是$D_{q}$，因为可能有些文档用户还没判断。
~\cite{hayes2006advancing}使用标准Rochio~\cite{Yates1999IR} 反馈处理算法，在下一轮迭代中修改查询向量各词项的权重，公式如下：
\begin{align}
    q_{new} = \alpha \cdot q +(\dfrac {\beta}{R} \sum_{d_{j} \in D_{r}}d_{j}) - (\dfrac{\gamma}{S}\sum_{d_{k}\in D_{irr}}d_{k} )
\end{align}

直觉上，通过将相关文档中出现的词项加到查询语句中可以使得查询语句与其它相关文档共享更多的词项，从而提高完全率；削弱查询语句中在不相关文档中出现词项的权重，可以使得查询语句远离不相关文档，进而减小犯错的概率，增加准确率。上式子中，可以通过调整参数 $\alpha$ 、 $\beta$ 、 $\gamma$ 来改变原始查询语句、相关文档和不相关文档对生成新查询语句的重要性。新查询语句生成之后，重新使用信息检索方法并对检索得到的相关文档按相似度排序，重复以上过程，直到用户取得满意的结果。然而后续工作
~\cite{Lingjun2009Refinement} 发现在做需求追踪时用Rochio反馈处理方法只有在前几次迭代中会提高准确率和完全率。

~\cite{Lucia2006Incremental}表明标准Rochio反馈处理方法对信息检索方法生成排序表的优化并不明显，尤其是当查询语句和文档语料质量比较好，使得信息检索的结果质量比较高时，Rochio 反馈处理方法对信息检索的结果几乎起不到任何优化作用，对于其它软件制品之间做可追踪性（例如用例和UML图之间）使用Rochio 方法不仅不能提升排序表的效果反而可能会让效果并得更差。~\cite{Zhang2012The} 对在
~\cite{hayes2006advancing} 的基础上对不同查询语句进行了分类，与~\cite{hayes2006advancing} 使用固定的参数 $\alpha$ 、 $\beta$ 、 $\gamma$ 不同， ~\cite{Zhang2012The}根据分类采用不同的参数并取得一定的效果。根据~\cite{Manning2008Introduction}，使用用户反馈（relevance feedback）信息提高对查询语句的检索效果要基于两个前提条件：
\begin{enumerate}
   \item Rocchio算法基于的假设是：查询语句与目标文档相比，词项比较少。
   \item 与查询语句相关的文档之间相似度比较高，假如对查询和文档进行分析，查询和相关文档应该能聚到同一个类中（聚类假设）。
\end{enumerate}
~\cite{Panichella2015Adaptive}认为在需求追踪环境下以上两个前提假设均不成立，有些查询语句（需求的文本文档）词项比目标文档（代码文档）要多。因此像之前工作~\cite{hayes2006advancing,Lingjun2009Refinement,Lucia2006Incremental} 那样不考虑前提条件是否满足直接使用用户反馈。并且，聚类假设也不成立，根据相关文献~\cite{Lawrie2010Normalizing,Lawrie2011identifiers}，需求实体和代码实体往往使用不同的词典，需求实体往往使用问题领域词项，代码实体则使用技术领域词项和一些缩写同义词等。综上
~\cite{Panichella2015Adaptive}提出一种方法，只有查询语句的词项小于等于相关文档，并且用户判断的文档中与查询语句相关的文档比不相关的文档多时才对用户反馈使用Rocchio算法。详见算法~\ref{alg:ARF}~：

\begin{algorithm}[!htbp]
\caption{Adaptive Relevance Feedback (ARF)}
\label{alg:ARF}
List $\leftarrow$  initial~ranked~list~of~candidate~links \\
Classified $\leftarrow \emptyset$;  \\
\ForAll {artefact $i$}
{
    $TP_{i}$ $\leftarrow$ $\emptyset$;  \\ %带下标的以及特殊数学符号要用 $$圈起来
    $FP_{i}$ $\leftarrow$ $\emptyset$;  \\
}
\While {not ($stopping criterion$)}
{
    Get the link (s,t) on top of List \\
    The user classifies (s,t)           \\
    Classified $\leftarrow$ Classified $\cup$ \{(s,t)\}  \\
    \If {(s,t) is~correct}
    {
        $TP_{s}$ $\leftarrow$ $TP_{s}$ $\cup$ \{t\}  \\
        $TP_{t}$ $\leftarrow$ $TP_{t}$ $\cup$ \{s\}  \\
    }
    \Else
    {
        $FP_{s}$ $\leftarrow$ $FP_{s}$ $\cup$ \{t\} \\
        $FP_{t}$ $\leftarrow$ $FP_{t}$ $\cup$ \{s\} \\
    }
    Let $V_{s}$ be the set of terms in s \\
    Let $V_{t}$ be the set of terms in t \\
    \If {$\left|V_{s}\right|$ $\leq$ $\left|V_{t}\right|$ and $\left|TP_{s}\right|$ $\ge$ $\left|FP_{s}\right|$}
    {
        apply the standard Rocchio to s \\    %%绝对值这种，是看成一个整体在外面加$$
    }
    \Else
    {
        \If {$\left|V_{t}\right|$ $\le$ $\left|V_{s}\right|$ and $\left|TP_{t}\right|$ $\ge$ $\left|FP_{t}\right|$ }
        {
            apply the standard Rocchio to t \\
        }
    }
    Recompute the ranked List of links \\
    List $\leftarrow$ List $-$ Classified \\
}
\end{algorithm}

与上述工作从通过用户对候选线索的反馈结果优化排序不同，~\cite{Wang2018Term}基于n-gram模型对查询语句进行分析，对不同的词项采取不同的权重调整策略。（增大，减小，不变）。

与上述迭代式方法不同，~\cite{Antoniol2000Modelling,Penta2002RAD}先让用户判断一部分候选追踪线索，作为方法的训练集。具体来~说，
~\cite{Antoniol2000Modelling}使用一组被判断过的追踪线索（训练集）作为贝叶斯分类器的输入，通过对测试集进行学习来提高基于概率模型的信息检索方法的准确率。~\cite{Guo2017deep}提出了一种使用嵌入词项和RNN技术的神经网络结构来生成软件制品之间相关性的方法。与基于信息检索的方法类似，该方法也会分析查询语句和目标文档的文本相似度，将用户已经判断过的追踪线索作为训练集作为方法的输入。相对于传统的基于VSM 和LSI模型的信息检索方法，~\cite{Guo2017deep} 方法得到的结果分别提高了41\%和32\%。但是该方法需要45\%的测试集和10\%的用户已经判断的追踪线索对通过训练集得到的分类模型进行优化。即用户需要判断所以候选追踪线索的55\%。这在实践中会耗费大量的用户精力。

\section{结合代码依赖关系}
在基于信息检索方法对需求到代码的可追踪性生成过程中，往往因为词汇失配问题（需求往往使用领域相关词汇，代码往往使用缩写，同义词，专业术语等）使得生成追踪列表的精度（准确率，召回率）有限。本小节主要介绍使用代码依赖信息对信息检索得到的排序表进行优化，弥补词汇失配问题的一些相关工作。

对于基于信息检索方法生成的候选追踪线索列表，~\cite{mcmillan2009combining}利用代码依赖关系对列表重排序。我们的之前工作
~\cite{kuang2015can}
对代码依赖进行了细分，直接依赖（类之间的继承、使用和方法之间的调用）、数据依赖（类之间的数据共享），并且认为直接依赖表达的是软件的控制流，数据依赖表达的是软件的数据流。~\cite{kuang2015can}表明对于需求到代码的可追踪性生成，代码元素直接的直接依赖和数据依赖起到互补的作用，两者相结合要比只使用其中一种取得更好的效果。后续工作~\cite{Kuang2017closeness}对代码依赖之间的紧密度进行了量化。对于代码之间的直接依赖，该工作认为两个类交互越越多并且和两个类和其它类交互的越少，则这两个类之间的代码依赖紧密度越高，公式如下：
\begin{align}
    Closeness_{DC} = \dfrac {2N}{WeightInDegree_{Sink}+WeightOutDegree_{Source}}
\end{align}
其中$N$表示类$Sink$和$Source$之间方法调用和类使用的次数，$WeightInDegree_{Sink}$表示类$Sink$被调用或使用的次数，
$WeightOutDegree_{Source}$表示类$Source$调用或使用其它类的次数。$Closeness_{DC}$位于区间[0,1]，该值越大表明两者关系越紧密。~\cite{Kuang2017closeness}基于信息检索技术并结合代码依赖紧密度分析做需求和代码之间的可追踪性并确的一定成果。
%~\cite{分数高的基本是正确的候选追踪线索}，
~\cite{Kuang2017closeness}的方法是对于给定查询语句，对检索结果进行排序。排在第一位的文档往往是有效的
%~\cite{分数高的基本是正确的候选追踪线索}
。根据其它文档与排在第一位文档的代码依赖紧密度，调整它们在排序表的位置。该工作包含两个步骤，首先设定代码依赖紧密度阈值，并由与排名第一的文档紧密度大于阈值的文档组成一个初始地域，详见算法~\ref{alg:initRegion}，修改域内文档（这里是类）与查询语句（需求）的紧密度。
\begin{algorithm}[htbp]
\caption{Establishing Initial Region}
\label{alg:initRegion}
initialRegion $\leftarrow \emptyset$; \\
prunedGraph $\leftarrow$ CDCGraph.setPruning$(Threshold_{DC},Threshold_{CD})$; \\
topLink $\leftarrow$ candidateList.next();  \\
\While {$prunedGraph.hasNoNeighbors(topLink.class)$}
{
    initialRegion.add(topLink.class); \\
    topLink $\leftarrow$ candidateList.next(); \\
}
initialRegion.add(topLink.class); \\
initialRegion.topIRValue $\leftarrow$ topLink.IRValue; \\
reachedClasses $\leftarrow   \emptyset$; \\
reachedClasses.add(prunedGraph.getTransitiveCallers(topLink.class)); \\
reachedClasses.add(prunedGraph.getTransitiveCallees(topLink.class)); \\
reachedClasses.add(prunedGraph.getNeighborsByData(topLink.class)); \\
\ForEach {$link in candidateList$}
{
    \If {$reachedClasses.contained(link.class)$}
    {
        link.IRValue $\leftarrow$ initialRegion.topIRValue; \\
        initialRegion.add(link.class); \\
    }
}
candidateList.reorderByIRValue();
\end{algorithm}

此外对于域外类，可能存在域内类到域外类的调用或者被调用关系，或者域外类和域内某些类存在共享数据。通过算法~\ref{alg:reRankOutSideRegion}改变域外相关类与需求的相似度。

\begin{algorithm}[!htbp]  %%%这里面的分数貌似要全部用$$包起来 并且只用一堆$$就够了
\caption{Re-rank Links outside Initial Region} %特殊符号 $\times$
\label{alg:reRankOutSideRegion}
topIRValue $\leftarrow$ initialRegion.topIRValue; \\
\ForEach {($link in candidateList$)}
{
    \If {$!initialRegion.contains(link.class)$}
    {
        \ForEach {$c in initialRegion$}
        {
            pathList $\leftarrow$ findValidPaths(link.class,c); \\
            $gMean$ $\leftarrow$ 0; \\
            \ForEach {$path in pathList$}
            {
                $gMean$ $\leftarrow$ max(GeometricMean($Closeness_{DC}$(path)),$gMean$); \\
            }
            link.IRValue $\leftarrow$ link.IRValue + $gMean$ $\times$ ($topIRValue-link.IRValue$); \\
            \If {$hasDataDependencies(c,link.IRValue)$}
            {
                link.IRValue $\leftarrow$ link.IRValue + (topIRValue-link.IRValue) $\times$ $Closeness_{CD}(c,link.class)$ ;\\
            }
            \If {$link.IRValue>topIRValue$}
            {
                link.IRValue $\leftarrow$ topIRValue; \\
            }
        }
    }
}
candidateList.reorderByIRValue(); \\
\end{algorithm}

\section{结合用户反馈和代码结构信息}
~\cite{panichella2013and} 认为对于使用代码结构信息来调整候选追踪列表的方法~\cite{mcmillan2009combining}，其最好的效果和信息检索方法得到的候选追踪线索排序表有很大关系。~\cite{mcmillan2009combining}当某个文档和查询语句相似度比较大时，此时增大与文档存在结构依赖的其他文档与查询语句的相似度。但是在文档文本质量比较差的情况下。如果与查询语句相似度比较大的文档本身和查询语句就没有相关性，此时利用代码依赖就会将错误扩大，对信息检索方法得到的候选追踪线索排序表造成污染。~\cite{panichella2013and}提出，每次将排序表顶端的追踪线索交由用户（软件工程师）判断，只要用户判断给追踪线索有效的时候才提高与该追踪线索具有代码依赖的其它追踪线索的相似度值。与~\cite{hayes2006advancing,Lucia2006Incremental,Panichella2015Adaptive}不同，~\cite{panichella2013and}不会改变词项的权重，因此不需要每次重新计算相似度。该方法相似步骤见算法~\ref{alg:UD_CSTI}
\begin{algorithm}[!htbp]
\caption{User-Driven Combination of Structural and Textual Information ― UD-CSTI}
\label{alg:UD_CSTI}
    \While {not (stopping criterion)}
    {
      Get the link ($s$, $c_{j}$) on top of List\\
      The user classifies ($s$, $c_{j}$)\\
       \If {$s$, $c_{j}$ is correct}
       {
          \ForAll {$c_{t} \in C$} {
            \If {$(c_{j}, c_{t}) \in E$} {
              Sim($s$, $c_{t}$) $\leftarrow$ Sim($s$, $c_{t}$) + $\delta$ $\times$ Sim($s$, $c_{t}$)
            }
          }
       }
      Reorder List\\
      Hide links already classified
    }
\end{algorithm}

其中$\delta$为相似度奖励系数，用来调节相关追踪线索相似度的变化程度。对于不同的追踪列表，该变量应该取不同的值，考虑到当候选列表的值分布比较集中时，该值稍微大一点就会使得相关候选追踪线索相似度值调整之后的排序会发生很大的变化；当候选列表的值分布比较发散是，该值过小可能使得相关线索虽然小相似度值增大，但是对其再排序表的位置确影响不大。该方法提出自适应的$\delta$。
\begin{align}
    \delta = median\{v_{i},...,v_{n}\}
\end{align}
其中$v_{i}=(max_{i}-min_{i})/2$，$v_{i}$与第$i$个查询文档对应目标文档的相似度最大值和最小值。


\section{需求追踪数据集（RTM）构造}
~\cite{Cleland-Huang2011challenges}需求追踪领域面临的一个挑战是，当研究者想验证自己方法有效性时，需要搭建基线方法的实验运行环境，这个过程会耗费大量精力，并且有些可追踪数据集往往不公开。~\cite{Charrada2011Benchmark}认为用于方法验证的可追踪性数据集比较少，研究者为了验证自己方法有效性往往需要自己做数据集，这个过程很耗时间。~\cite{Charrada2011Benchmark}公布了一个针对一个灌溉系统的数据集，包括了改系统各种软件制品之间的追踪关系。同时通过用同样的方法对该数据集和领域内常用的数据集进行处理，比较它们precision/recall图像的相似性，验证该数据集的有效性。~\cite{Chen2013Robust}提出一个概率模型，以帮助用户建立可靠的数据集并公开了他们采用这种方法构造的JDK1.5的数据集。

上述方法均为纯人工构造数据集的方法，敏捷开发领域，项目往往采用一些任务管理工具（issue tracker）来管理需求。用代码版本控制工具（例如CVS、SVN、GIT）来管理代码，图~\ref{F:openSourceStructure}
\begin{figure}[thb]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/related_work/Open_Source_Structure.pdf}
    \caption{开源软件结构图}
    \label{F:openSourceStructure}
\end{figure}
主要由两部分组成：需求管理系统（这里以jira为例），代码版本控制系统（这里以github为例）。用户在需求管理系统提交软件相关的bug或者新的需求（new feature）。研发人员会对用户所提交的issue进行评审以决定是拒绝接受该issue还是完成该issue。如果是后者接下来用户会完成与issue相关的代码（可能是完成某个需求也可能是修复某个bug）。然后用户会将更改的代码提交到github，并在commit 信息中表述该新增或修改代码的功能。很自然的这里issue和提交的代码就形成了追踪关系。~\cite{Shi2017linguistic}对需求管理系统中的new feature文本进行了分类，使得我们对new feature能有更好的利用。



\section{本章小结}
本章介绍了过时需求自动检测的相关技术，并分析了现有方法的不足。同时，本章介绍了在需求可追踪性、概念定位等相关领域，已有工作如何结合代码依赖关系与信息检索以提高原有方法的精度。

