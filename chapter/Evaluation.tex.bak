\chapter{基于代码托管平台的数据组织及方法验证}
本章通过设计实验来验证第三章所述方法的有效性和实用性。如相关工作所述，当前当前领域内公开用于验证可追踪方法的数据集通常是一些人工标注的小型系统数据集。本章~\ref{sec:data_arrange}节通过分析整理由代码托管平台（本章中的代码托管平台为github）管理的开源软件在issue-tracking 工具（本章中的issue-tracking工具为Jira）的行为信息得到了其需求到代码的追踪关系。
通过运行软件系统自带的用于验证自身功能的测试用例得到本文方法所需的高质量代码依赖集。本章~\ref{sec:methodValidate}节中的使用一个被领域内广泛用于软件可追踪方法验证的
高质量数据集iTrust~\cite{iTrust}和三个被广泛用于日常生活实践的开源软件系统Maven~\cite{Maven}、Pig~\cite{Pig}
和Infinispan~\cite{Infinispan}来对本文方法进行验证，该小节选取了一些领域内常用的度量指标将本文的方法效果和基线方法对比，并对实验数据进行了细致分析。实验表明，本文的方法只需少量的（3.5\%）用户反馈信息在精度上即可显著优于基线方法。
\section{数据组织}
\label{sec:data_arrange}
如前文所述，一方面，我们的方法需要基于日常实践的可追踪数据集来验证其实用性；另一方面，高质量的代码依赖信息是我们方法的重要输入。本节首先在~\ref{sec:sec:buildRTM}节介绍开源软件需求到代码可追踪数据的构造过程，然后在~\ref{sec:sec:code_dependency_capturer}节介绍了对于由不同构建工具管理的开源软件，如何通过对其配置文件进行相应配置使得能够将代码依赖捕获工具插桩到运行其测试集的虚拟机中，进而动态获得其代码依赖子集，最后，对代码依赖子集进行合并得到代码依赖。
\subsection{用于方法验证的可追踪数据集组织}
\label{sec:sec:buildRTM}
本小节主要介绍~\ref{sec:methodValidate}节中所用开源软件需求到代码可追踪数据集的构造过程。我们选取的Maven、Pig和Infinispan在github 
~\cite{github}更新活跃，吸引了大批贡献者。当前大量Java项目由Maven构建工具来管理，Infinispan作为分布式缓存系统则被大量工业集群使用，Pig作为一个大数据处理平台被广泛用于大数据开发中。这三个开源软件由issue-tracking工具JIRA~\cite{Pohl2010Requirements}来管理其软件行为变更信息（bug 反馈、需求变更和增加新需求等），被广泛用于缺陷定义、客户服务、需求收集、流程审批、任务跟踪和敏捷管理等领域。在JIRA 中用issue 来描述软件行为信息。以Pig为例，图~\ref{F:issue_pig_4963}为
\begin{figure}[thb]
    \centering
    %\setlength{\abovecaptionskip}{0pt}
    %\setlength{\belowcaptionskip}{2pt}
    %\includegraphics[width=3in]{./figures/evalution/issue_pig_4963.pdf}
    \includegraphics[width=1.0\textwidth]{./figures/evalution/issue_pig_4963.pdf}
    \caption{JIRA上的一条issue信息}
    \label{F:issue_pig_4963}
\end{figure}
为实验系统Pig在JIRA上的一个issue信息，根据该issue的类型我们知道该issue描述的软件行为信息是增加新功能。通过issue的描述信息我们得知该功能是用来解决大数据的处理问题，以及具体是解决方案是添加一个bloom join是实现。此外，issue还包含大量其它信息，例如issue的优先级，会影响的版本，issue当前的状态等。我们会综合利用这些信息筛选出描述需求的issue。
上述开源软件Git~\cite{Fischer2003Populating}来管理其代码变更信息，Git是一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理。通常用户在issue-tracking工具提交issue 之后，软件研发人员会对issue 进行评审以决定是拒绝还是接受该issue。如果是后者，软件研发人员会针对该issue完成相应代码变更，并将代码提交到代码托管平台。
\begin{figure}[thb]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/evalution/issue_pig_4963_commit.pdf}
    \caption{针对issue的git commit}
    \label{F:issue_pig_4963_commit}
\end{figure}
图~\ref{F:issue_pig_4963_commit}为针对图~\ref{F:issue_pig_4963}所示issue的一次代码提交（commit）。
Git记录了该commit所引起的代码变更（我们这里只看.java结尾的文件，因为我们的对源代码的研究粒度是java类）。
由图可知，这里变更的文件有~PigConfiguration.java、~MRCompiler.java和~PigCombiner.java 等。我们能很自然的得出issue PIG-4963所描述的需求与以上java 类存在追踪关系。这也是我们为Pig、Maven和Infinispan建立需求到代码可追踪数据集的思路来源。

~\cite{Rath2017IlmSeven}用8张数据库表对开源项目在Git和JIRA的信息进行了分类整理（表~\ref{dataset_table}描述了各数据表的内容）。
\begin{table}[htbp]
  \centering
  \caption{开源系统数据整理}
  \label{dataset_table}
  \begin{tabular}{@{}ll@{}}
  \toprule
  table      & description  \\ \midrule
  issue      & 记录每个issue的具体信息，标识符、描述信息、类型、时间戳等         \\
  issue\_link & 记录issue之间的关系，例如从属、依赖、重复等                       \\
  issue\_component &  记录改issue所属的模块                                       \\
  issue\_fix\_version & 记录改issue被完成的版本                                    \\
  chang\_set         & 一个代码提交的相关信息，代码提交者、时间戳、描述代码提交的文本   \\
  chang\_set\_link    & 该表记录代码提交和issue之间的对应关系 \\
  code\_chang        & 一次代码提交引起的代码文本变更，例如增加或减少了哪些代码               \\
  project         & 项目的元数据，包含JIRA和git仓库的信息                                    \\ \bottomrule
  \end{tabular}
\end{table}

我们通过对这些数据库表进行连接与合并等相关操作（图~\ref{F:build_rtm}为我们对数据库表的操作流程），最终得到需求到代码的追踪关系。具体来说，首先，我们对设置规则对issue进行过滤筛选，得到描述需求的issue，issue筛选规则如下：
\begin{enumerate}
  \item 忽略带有关键词testing或者testcase的issue，因为这些issue往往是和测试用例有关系，不是软件系统的功能性需求。
  \item issue必须已经被完成并且有与之关联的code\_change，只有这样我们才能生成需求（issue）到代码的追踪关系。
  \item 我们只选择优先级为Major和Critical的issue，因为这些往往是重要的系统功能性需求。
  \item 我们只选择类型为New Feature（或Feature Request）的issue，这种类型的issue通常用来描述系统功能性需求~\cite{Heck2013trackers,Shi2017linguistic}。并且这种需求粒度比较接近传统的需求（例如iTrust的需求），类型为Bug的issue 往往粒度太小，类型为Task的issue又往往粒度过大。
\end{enumerate}
接下来，我们通过对筛选之后的数据库表~issue和数据库表~chang\_set\_link做连接操作，得到~issue和代码提交之间的关联关系，每一次代码提交都用一个全局唯一的hash来表示。同时，我们通过对数据库表~change\_set和~code\_change做连接操作得到代码提交和代码变更之间的对应关系，然后我们通过对以上生成的两个中间数据库表进行连接操作即可得出~issue和代码变更之间的追踪关系。最后根据表~issue\_link中描述的issue 之间的关系，我们将关系为从属（~part-of）、重复（~duplicate）、替代（~supersede）的~issue对应追踪线索进行合并。最终，我们得到了需求（issue 中用来描述软件行为的~description文本）和代码（Git中与~issue对应的代码变更）之间的追踪关系。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/evalution/buildRTM.pdf}
    \caption{需求到代码追踪关系整理过程}
    \label{F:build_rtm}  %%关键词不变色有时是因为拼写有问题
\end{figure}
%本文主要使用issue、~issue\_link、~change\_set、~code\_change和~chang\_set\_link五张表来合成RTM数据集，

\subsection{用于方法输入的代码依赖数据组织}
\label{sec:sec:code_dependency_capturer}
本小节首先对本文使用的代码依赖捕获工具~\cite{kuang2015can}进行简要介绍，然后介绍由不同构建工具管理的软件系统，通过运行其用于验证自身系统功能的测试用例得到其对应代码依赖的过程。
图~\ref{F:code_dependency_capturer}为我们代码依赖捕获工具的结构图，其基本原理是：使用标准JDK 提供的JVMTI接口，监听Java 虚拟机中产生的四个JVMTI 事件：类成员读取事件、类成员修改事件、函数进入事件以及函数返回事件并注册这四个事件的回调函数，在回调函数中将事件引起的函数进入、返回记录和数据访问记录保存到本地数据库中。最终，通过对这些数据进行分析处理得到我们所需的代码依赖。我们通过对软件系统所用的构建工具进行相应配置，使得在运行测试其测试用例时，代码依赖捕获工具会插桩到运行该测试用例的虚拟机中，进而得到软件系统对应的代码依赖信息。
代码依赖工具得到的是方法级代码依赖，而我们实验中需要用到的是类级别的代码依赖，因此我们将方法级代码依赖按照如下规则转化为类级别代码依赖：
\begin{enumerate}
  \item 类之间调用依赖关系从方法调用依赖关系中抽象出来，调用边的权值为发生不同方法调用的次数。
  \item 类之间数据依赖关系从方法数据依赖关系中抽象出来，数据依赖边的权值为两个类之间共享数据类型的个数。
  \item 类之间使用关系从方法之间数据依赖关系中抽象出来。
  \item 类之间继承关系从方法调用中得到，子类在调用自己的构造方法之前会去调用其父类的构造方法。
\end{enumerate}

我们基于如下原因选取该工具：
\begin{enumerate}
  \item 虽然能够捕获函数调用的动态分析工具很多（例如著名的The Eclipse Test \& Performance Tools Platform，TPTP；或Java Plug-in Framework，JPF），但是这些工具都不能捕获函数之间的数据共享。
  \item 基于java虚拟机的运行时检测，这个工具可以捕获实际执行的代码依赖关系并正确处理多态。由于该工具是在系统运行时刻对系统实际行为的观察与记录，因此不会产生非正确的代码依赖关系。
  \item 该工具可以在一次系统运行中同时获得以上四种代码依赖，由于所执行测试集合的不完备性，动态分析无法保证捕获的代码依赖关系的完整性，虽然这一问题无法避免，但是我们认为部分确实的代码依赖关系在其缺失程度大致相同的情况下，并不会影响最终的实验结果，其原因在于我们用一个整合的工具在运行相同测试集合的时候同时捕获函数调用和数据依赖。
\end{enumerate}

%我们通过jvm参数-agentpath将该工具插桩到运行目标测试集的虚拟机中。
\begin{figure}[hthb]
    \centering
    \includegraphics[width=0.9\textwidth]{./figures/evalution/code_dependency_capturer.pdf}
    \caption{代码依赖捕获工具结构图}
    \label{F:code_dependency_capturer}
\end{figure}
最终我们便可得到目标系统的代码依赖信息。综上所述，通常我们获取代码依赖的方式是运行目标代码，将我们的代码依赖捕获工具插桩到运行目标代码的虚拟机中，然后我们对捕获的数据进行处理，最终得到代码依赖信息。接下来我们将阐述本文实验中的所用实验系统的代码依赖捕获过程。

本文中的实验系统分为两类：一种是iTrust这样的应用软件，它是一个医疗管理软，能独立运行。我们运行该系统同时插桩代码依赖捕获工具，根据用户手册来运行该系统具有的各种功能从而捕获尽可能完整的代码依赖。另一种是Pig、Maven、Infinispan这样的支撑软件，
%（见表~\ref{T:SoftwareInfo}）
与应用软件不同，使用这些支撑软件的多种功能并不容易。观察得知，本文实验系统中的开源支撑软件具有如下结构特点：
\begin{enumerate}
  \item 具有丰富用于验证自身系统功能的测试集合。（图~\ref{F:codeDepFromSubCodeDep}为infinispan的结构图，每个模块都有相应测试集）
  \item 采用构建工具maven或ant管理
\end{enumerate}

因此，我们提出通过运行软件系统用于验证自身功能的测试用例得到方法所需代码依赖的方法。具体来说，首先，通过运行软件系统各模块的测试用例得到代码依赖子集，然后，我们根据一些合并规则对代码依赖子集进行合并，最终得到第三者章所述软件可追踪生成方法所需的代码依赖。该方法简单高效，不需要软件系统能够独立运行，并且可以通过构建工具批量运行测试集。
图~\ref{F:codeDepFromSubCodeDep}为该方法的流程图。
\begin{figure}[thb]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/evalution/captureCodeDepFromSubCodeDep.pdf}
    \caption{运行测试用例捕获代码依赖的过程}
    \label{F:codeDepFromSubCodeDep}
\end{figure}

本文实验中涉及到的基于日常实践的开源系统由两种构建工具来管理：Maven、Ant~\cite{ant}。接下来，我们将在
~\ref{sec:sec:sec:manageByMaven}节和~\ref{sec:sec:sec:manageByAnt}节分别介绍这两种构建工具下的代码依赖捕获过程。
\subsubsection{由Maven管理的软件系统代码依赖获取}
\label{sec:sec:sec:manageByMaven}
构建工具Maven是一个跨平台的项目管理工具，本身是一个Java开源项目。Maven 主要服务于基于Java平台的项目构建、依赖管理和项目信息管理。Maven 帮助我们标准化构建过程，抽象了一个完整的构建生命周期模型，每个生命周期都由相应的插件来负责。
Maven在运行测试集发生在测试阶段，该阶段由surefire插件负责。
%我们通过调研发现通过maven管理的软件，其测试集由surefire插件运行。
当执行$mvn~test$命令时，surefire插件会运行所有以Test结尾的类，我们将代码依赖捕获工具插桩到运行测试集的虚拟机中即可获得测试集对应的代码依赖捕获数据。需要说明的是：在Maven 的测试周期，默认情况下Maven会开启新的虚拟机进程用来运行测试集，而不是用运行Maven的虚拟机运行测试集。即我们需要把工具插桩到运行测试集的虚拟机中。通过阅读maven-surefire-plugin~\cite{surefire}文档，我们通过对surefire模块两个重要参数的配置完成工具插桩进而完成代码依赖的捕获。
\begin{enumerate}
  \item forkCount 用来指定运行测试集的虚拟机进程数目，默认为1。如果该数字以C结尾，运行虚拟机的进程数目为这个数字乘以CPU 内核数。如果该数字设置为0，则意味着不在启动新的虚拟机进程运行测试集，由主虚拟机进程（运行Maven的虚拟机）来执行测试集。
  \item argLine 设置jvm启动参数
\end{enumerate}

基于以上内容我们有两种方法通过运行测试集捕获代码依赖：（1）配置pom文件里的maven-surefire-plugin插件，通过$argLine$将工具插桩到运行测试集的虚拟机中。（2）通过设置forkCount参数为0，用运行maven的虚拟机进程来运行测试集，此时在启动Maven时插桩代码依赖捕获工具即可。
接下来我们通过对代码依赖子集进行合并得到软件对应的代码依赖，代码依赖合并规则如下：
\begin{enumerate}
  \item 对于直接代码依赖：在测试用例1中存在A调用B，在测试用例2中存在B调用C，由此我们可以得出A调用C。 
  \item 对于数据依赖：在测试用例1中存在A和B同访问类型为D的数据，在测试用例2中存在B和C同访问数据类型为D的数据，则A,B,C共享数据类型D。
\end{enumerate}

\subsubsection{由Ant管理的软件系统代码依赖获取}
\label{sec:sec:sec:manageByAnt}
构建工具Ant最早用来构建著名的Tomcat，我们可以将Ant看成是一个Java版本的Make，Ant使用XML定义构建脚本，相对于~\emph{Makefile} 更加友好。Ant可以用junit ~\cite{junit}框架来运行软件的测试集。在运行测试集的过程中为了捕获代码依赖我们需要将代码依赖捕获工具插桩到运行测试集的虚拟机中。与~\ref{sec:sec:sec:manageByMaven}类似
这里介绍以下junit的两个重要参数：fork、jvmarg。
\begin{enumerate}
  \item fork 当开启此参数（fork=“yes”）时，Ant会启动新的java虚拟机来执行测试集
  \item jvmarg 当开启参数fork时，jvmarg用于向这个新开启的虚拟机传递jvm参数
\end{enumerate}
基于以上内容，与被构建工具Maven管理的项目类似，我们有两种方法通过运行用Ant管理的软件系统的测试集得到代码依赖：（1）配置文件build.xml 中的junit，开启fork参数并通过jvmarg参数向新开启的虚拟机传递jvm参数 （2）配置文件build.xml中的junit，不开启fork 参数（fork=“false”），此时在启动Ant时插桩代码依赖捕获工具即可。
在我们的实验中，我们都是采用第一种方法插桩代码依赖捕获工具获取代码依赖子集，这是因为我们使用的代码依赖捕获工具为单线程，如果采用第二个方法会出现几个进程同时向数据库写数据的同步问题。

%\section{结合代码依赖紧密度分析和用户反馈的软件可追踪生成方法}
\section{方法验证}
\label{sec:methodValidate}
本节我们通过实验以验证结合代码依赖紧密度分析和用户反馈的软件可追踪方法的有效性。接下来，将具体阐述我们的实验设置及实验结果与分析。
\subsection{实验系统}
我们的实验部分是基于四个现实世界、来自不同领域的软件系统。iTrust（在线医疗档案管理）、Maven（构建管理工具）、Pig（编译器）、Infinispan（数据库）。iTrust是在这个领域内被广泛使用的数据集，其软件可追踪数据集由系统开发与维护人员提供。但是该系统提供的高质量数据集是方法粒度的，即表达的是需求和方法之间的追踪关系。而本文的方法是基于类粒度的，因此在iTrust中，我们将需求和方法之间的追踪关系转化为需求和类之间的追踪关系。我们的转换规则是：若需求和方法之间有追踪关系，则我们认为需求和这个方法所在的类有追踪关系。其它三个实验系统通过~\ref{sec:sec:buildRTM}节所述方法获取其软件可追踪数据集。
表~\ref{expirement_system_information}列举了这四个实验系统的基本信息。
\begin{table}[htbp]
\centering
\caption{实验系统的相关细节}
\label{expirement_system_information}
\begin{tabular}{@{}lcccc@{}}
\toprule
                  & iTrust & Maven & Pig     &   Infinispan    \\ \midrule
  版本            & 13.0   & 3.5.2 & 0.17.0  &     9.2.0       \\
  编程语言        & Java   & Java  & Java    &     Java        \\
  千行代码（KLoC）& 43     & 101   & 365     &     521         \\
  代码（类）      & 138    & 94    & 236     &     388         \\
  需求（用例）    & 34     & 36    & 68      &     237         \\
  需求对应类的平均数 & 8   &  4    &  5      &     6           \\
  调用依赖        & 274    & 182   & 1998    &     1777        \\
  数据依赖        & 4792   & 1164  & 5405    &     6076        \\
  追踪关系        & 255    & 155   & 356     &     1515        \\ \bottomrule
\end{tabular}
\end{table}

\subsection{评价指标}
\label{sec:sec:traceability_recovery_goal_metrics}
为了验证我们结合代码依赖和用户反馈方法的有效性和实用性，我们首先引入领域内常用的两个重要度量，精确度（precision）和查全率（recall）。
对应公式如下：
\begin{align}precision=\dfrac {\left| relevant\cap retrieved\right| } {\left| retrieved\right| }\% \end{align}
\begin{align}recall=\dfrac {\left | relevant \cap retrieved \right |} {\left| relevant\right| }\% \end{align}
参数解释：其中~\emph{relevant}是相关的候选追踪线索集合。~\emph{retrieved}表示软件可追踪生成方法所返回的候选追踪线索集合。由于自动化可追踪生成方法所返回的是一个候选追踪线索排序列表，即按照文本相似度值从高到低排序。所以一种常用的比较方法的方式是在不同的查全率下比较不同方法之间的精确度，可以由一条~\emph{Precision-Recall}曲线展示。为了进一步衡量不同自动化软件可追踪生成方法返回结果的整体质量，我们选用了领域内另外两个常用指标：AP（Average Precision）与MAP（Mean Average Precision）。其中
~\emph{AP}用于度量全部查询（需求）所检索相关文档的排序质量，计算公式如下：
\begin{align}
  AP=\dfrac {\sum _{r=1}^{N}\left( Precision\left( r\right) \times isRelevant\left( r\right) \right) } {\left|
  RelevantDocuments\right| }
\end{align}
参数解释：~\emph{r}表示被查询实体（类）在排序表中的位置，N表示候选追踪线索的总数。~\emph{Precision(r)}表示对于前~\emph{r} 个候选追踪线索的准确率。~\emph{isRelevant()}为一个二值函数，如果这条候选线索有效则返回1，否则返回0。此外，~\emph{MAP}用于描述不同查询（需求）所检索的相关文档（类）~\emph{AP}的平均值。计算公式如下：
\begin{align}
MAP=\dfrac {\sum _{q=1}^{Q}AP\left( q\right)} {Q}
\end{align}
参数解释：~\emph{q}表示一次查询而~\emph{Q}表示查询的总数。为了更全面的验证方法有效性，我们同时使用~\emph{AP}和~\emph{MAP}两个度量指标。

\subsection{阈值设置}
\label{subsec:calibrate_threshold}
我们需要校准四个阈值，$Threshold_{idtf}$、$Threshold_{DC}$、$Threshold_{CD}$和LSI的$k$值。根据之前的
~\cite{Kuang2017closeness,kuang2015can}案例分析，我们设置$Threshold_{idtf}$的值为1.4，用这个阈值来忽略普遍出现的数据类型。   %%%特殊数学符号用$$
对于$Threshold_{DC}$和$Threshold_{CD}$的设置，我们首先使用3$\sigma$  标准分别去除$Closeness_{DC}$和$Closeness_{CD}$集合中的异常值。我们这里的异常值定义为：比集合标准差 $\sigma$ 高三倍或者低三倍的紧密度值。然后通过min-max标准化我们将剩余的代码依赖紧密度归一化到[0,1]区间。之前被过滤掉的高异常值此时设置为1，类似的之前被过滤的低异常值被设置为0。
对于$Threshold_{DC}$和$Threshold_{DC}$ 的值的选取，我们根据~\ref{sec:sec:traceability_recovery_goal_metrics}中的度量指标，在[0,1] 区间选取一组能让所有实验系统在不同信息检索模型下综合表现最好的阈值。本文中设置$Threshold_{DC}$ 为0.4，$Threshold_{CD}$为0.8。

对于代码依赖紧密度，经过min-max标准化处理之后的值，仅用于设定阈值生成代码依赖域。对于算法~\ref{alg:reRankCandidate}我们还是用原始的代码依赖紧密度值。对于LSI方法中的K值，我们发现当k为90时iTrust和Maven的~Precision/Recall表现最好，而对于Pig和~Infinispan，k值取200 时~Precision/Recall表现最好，从表~\ref{expirement_system_information}中可以看出~iTrust和~Maven数据集中需求的个数比较接近（94和138），Pig和~Infinispan的需求比较接近（236和237）我们认为这是这两组系统在LSI模型下最优K值出现差异的原因。

\subsection{实验目标与研究问题}
\label{sec:sec:research_question}
我们的实验目的是分析结合我们的方法能否提高生成追踪线索列表的精度，为了达到这一目的，我们需要回答如下研究问题：\\
RQ: 在需求到代码的可追踪性生成场景下我们的方法能否优于基线方法？\\
为了回答这个问题，我们选择了以下三个基线方法：（1）只利用信息检索技术的纯信息检索方法（简称为IR-ONLY）；（2）基于信息检索方法，引入代码紧密度分析的方法（简称为TRICE~\cite{Kuang2017closeness}）；（3）基于信息检索方法，考虑代码结构信息和用户反馈信息的先驱方法（简称为UD-CSTI~\cite{panichella2013and}）。我们将我们的方法命名为CLUSTER（CLoseness-and-USer-feedback-based Traceability Recovery），在对比
CLUSTER和三个基线方法时，我们依次使用三种不同的主流模型（VSM、LSI和JS）。
同时本方法的另一个目标是尽量减少用户参与，即使用尽量少的用户反馈。所以，对于基线方法UD-CSTI，用户需要判断所有的追踪线索（我们方法中的用户判断环节通过软件可追踪数据集来模拟，即我们假设用户判断全部都是正确的）。而实验中我们的方法里需要用户判断的追踪线索不超过全部追踪线索的3.5\%。即对于给定需求，iTrust中需要判断四个类，Maven中需要判断三个类，Pig和Infinispan中需要判断八个类与给定需求的相关性。基于以上设置，通过比较UD-CSTI和CLUSTER来判断在我们的方法中是否少量的用户反馈就能起到明显的效果。
除了~\ref{sec:sec:traceability_recovery_goal_metrics}中提到的指标，我们还引入了统计显著性测试来判断CLUSTER是否显著比基线方法好。通过调研~\cite{Kuang2017closeness,Ali2015entities}中所设计的显著性测试。对于候选追踪列表，我们选择在每个有效追踪线索位置的F-measure 作为我们测试的单独依赖变量。选择F-measure的原因是我们想分析相比于基线方法，CLUTSRE方法能否同时提升查全率和准确率。
F-measure计算公式如下：
\begin{align} F=\dfrac {2} {\dfrac {1} {R}+\dfrac {1} {P}} \end{align}
参数解释：P表示准确率，R表示查全率，F是P和R的调和平均。从公式中可以看出准确率和查全率越大，F-measure的值越高。由于F-measure 在两个不同系统之间是成对存在的，因此我们使用Wilcoxon rank sum测试~\cite{Grogge2000Statistics}验证以下零假设：\\
$H_{0}$:CLUSTER和基线方法性能没有区别。\\
我们采用$p-value$显著性差异水平0.05作为衡量检验结果的标准。
\subsection{实验结果与分析}
\label{sec:result_and_discussion}
根据~\ref{sec:sec:traceability_recovery_goal_metrics}提出的度量指标，表~\ref{Metrics-Wilcoxon}展示了4个实验系统的实验结果。我们比较了CLUSTER和基线方法在这四个实验系统上的表现（$AP$，$MAP$与显著性检验的p-value值）。在36个实验结果对比中，有30个实验结果CLUSTER 的F-measure值明显优于基线方法（p-value$<$0.05并且AP值大于基线方法）。这表明在绝大多数情况下，相比基线方法，CLUSTER 提高了候选追踪列表的准确率和查全率。此外，对于实验系统iTrust 和Maven，CLUSTER方法的AP和MAP几乎全部优于基线方法。只有在Maven-VSM和Maven-LSI 上CLUSTER 方法的MAP 值略逊于TRICE。然而在Pig系统上CLUSTER方法只有在VSM模型下AP值优于UD-CSTI，其他情况下效果均不如基线方法UD-CSTI。但是从表~\ref{Metrics-Wilcoxon} 中可以看出两者差距比较小（差异小于0.5）。并且如前文所述CLUSTER
方法只需要用户判断3.5\%的追踪线索，而UD-CSTI方法需要用户验证所有的跟踪线索。图~\ref{F:precisionRecall}展示并对比了12种实验组合下的precision-recall曲线。
\begin{figure}[thb]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/evalution/precisionRecall.pdf}
    \caption{precision-recall图像}
    \label{F:precisionRecall}
\end{figure}



\begin{table}[htbp]
%\small   %tiny scriptsize footnotesize small normalsize large ...
\footnotesize
\centering
\caption{实验系统的评价指标及Wilcoxon秩和检验结果}
\label{Metrics-Wilcoxon}
\begin{tabular}{@{}ccccccccccc@{}}
\toprule
           &         & \multicolumn{3}{c}{VSM} &        \multicolumn{3}{c}{LSI} &        \multicolumn{3}{c}{JS} \\ \midrule
           &         & AP    &  MAP   & p-value       & AP    & MAP   & p-value        & AP    & MAP   & p-value        \\
iTrust     & IR-Only & 42.55 & 56.55 & \textless 0.01 & 41.21 & 55.73 & \textless 0.01 & 38.28 & 55.99 & \textless 0.01\\
           & UD-CSTI & 45.75 & 59.08 & \textless 0.01 & 45.42 & 59.35 & \textless 0.01 & 43.26 & 62.99 & 0.10 \\
           & TRICE   & 45.80 & 59.05 & \textless 0.01 & 45.18 & 58.76 & \textless 0.01 & 45.29 & 61.25 & 0.16 \\
           & CLUSTER & 52.10 & 63.28 &         -      & 51.60 & 63.21 &       -        & 46.56 & 63.29 &  -   \\
           \hline
Maven      & IR-Only & 20.66 & 38.59 & \textless 0.01 & 17.21 & 42.37 & \textless 0.01 & 19.45 & 40.70 & \textless 0.01\\
           & UD-CSTI & 21.68 & 39.42 & \textless 0.01 & 18.52 & 43.28 & \textless 0.01 & 22.12 & 42.10 & \textless 0.01 \\
           & TRICE   & 21.68 & 41.58 & \textless 0.01 & 16.85 & 46.17 & \textless 0.01 & 19.30 & 41.69 & \textless 0.01 \\
           & CLUSTER & 25.44 & 41.38 &         -      & 21.11 & 45.47 &       -        & 22.32 & 43.57 &      -         \\
           \hline
Pig        & IR-Only & 21.98 & 42.36 & \textless 0.01 & 19.88 & 42.25 & \textless 0.01 & 15.61 & 35.56 &    0.02  \\
           & UD-CSTI & 24.19 & 43.49 &    0.49        & 22.40 & 43.67 &      0.68      & 18.90 & 37.82 &    0.27 \\
           & TRICE   & 16.88 & 41.91 & \textless 0.01 & 15.85 & 40.72 & \textless 0.01 & 13.83 & 36.79 &    0.18 \\
           & CLUSTER & 24.64 & 43.32 &      -         & 22.30 & 43.19 &        -       & 18.88 & 37.57 &      -  \\
           \hline
Infinispan & IR-Only & 14.47 & 22.87 & \textless 0.01 & 14.15 & 22.98 & \textless 0.01 & 14.98 & 22.59 & \textless 0.01\\
           & UD-CSTI & 16.59 & 24.14 & \textless 0.01 & 17.95 & 24.76 & \textless 0.01 & 19.57 & 24.56 & \textless 0.01\\
           & TRICE   & 12.79 & 20.92 & \textless 0.01 & 12.96 & 21.84 & \textless 0.01 & 13.70 & 21.28 & \textless 0.01\\
           & CLUSTER & 18.47 & 23.82 &      -         & 18.61 & 23.91 &        -       & 19.86 & 23.24 & - \\\bottomrule
\end{tabular}
\end{table}
观察表~\ref{Metrics-Wilcoxon}和图~\ref{F:precisionRecall}，我们会发现TRICE方法的性能高度依赖通过纯信息检索方法生成候选追踪列表的质量。即TRICE方法依赖需求文本和代码文本的语料质量。在文本语料质量比较好的iTrust系统上，TRICE和UD-CSTI效果差异不大。但是在信息检索效果的AP和MAP 都比较低的Pig和Maven系统，TRICE方法明显不如UD-CSTI。在Pig-VSM和Pig-LSI，TRICE方法的性能甚至不如纯信息检索方法。
%正如~\ref{sec:relatework}讨论的，
没有用户反馈，TRICE方法只能把与给定需求相似度最大的类作为紧密度分析的输入，给与这个类代码依赖紧密度比较大的类对应追踪线索奖励。这种方法比较保守，然而也使得无法进一步提高基于信息检索方法的性能。例如在前面用例中，对于CLUSTER方法，用户需要判断两个域的代表类与需求相关性。如果相关会通过两个类向外扩散给与其依赖关系紧密的类对应候选线索奖励。此外，与给定需求相似度最大的类对应的追踪线索如果是无效的，在TRICE方法中由于没有用户反馈，按照TRICE方法会给与这个类紧密度比较大的类对应的追踪线索奖励。即此时这个错误会被放大最终使得被“优化之后的候选列表”准确率和查全率更低。在CLUSTER和TRICE方法中由于用户反馈的存在就避免了这种情况。实际上，我们观察到在12个实验中CLUSTER和UD-CSTI的效果均明显优于IR-ONLY，即便是在语料质量比较好的iTrust系统，情况也是如此。这表明在建立需求到代码的可追踪性时，用户反馈是一项重要的资源。

然而，使用用户反馈意味着用户需要付出额外的努力。正如前文提到的UD-CSTI 方法为了达到其最优效果需要用户判断所有的追踪线索，这是不实际的。而我们的方法CLUSTER只需要用户判断3.5\%的追踪线索（即对于给定需求，iTrust中需要判断四个类，Maven中需要判断三个类，Pig中需要判断8个类，Infinispan中需要判断8个类与给定需求的相关性。）就能达到与UD-CSTI类似的效果甚至优于UD-CSTI。这在基本不影响候选追踪线索列表效果的前提下大大减少了用户需要付出的努力。为了进一步比较CLUSTER方法的成本效益（成本是指用户做出判断花费的精力，效益是用户判断后候选追踪列表准确率和查全率的提高），我们比较不同查全率对应的精度和遇到的无关追踪线索数量（如表
~\ref{T:fp-reduce}）。

\begin{table}[htbp]
%\small
\footnotesize
\centering
\caption{不同查全率下的精度对比}
\label{T:fp-reduce}
\begin{tabular}{@{}cccccccccc@{}}
\toprule
&&\multicolumn{2}{c}{Recall(20\%)}&\multicolumn{2}{c}{Recall(40\%)}&\multicolumn{2}{c}{Recall(60\%)} & \multicolumn{2}{c}{Recall(80\%)} % & \multicolumn{2}{c}{Recall(100\%)}
\\ \midrule
           &     & Precision & FP  & Precision & FP & Precision  & FP  & Precision & FP  \\ % & Precision & FP \\
iTrust     & VSM & -46.59\% & +81 & -0.24\% & +1 &  +16.81\%  & -261 & +3.93\%  & -428   \\% & +0.22\% & -160 \\
           & LSI & -46.34\% & +80 & +6.40\% & -29 & +21.64\%  & -349 & +3.93\%  & -403 \\ % & +0.00\% &	0 \\
           & JS  & -46.59\% & +81 & +7.73\% & -41 & +11.48\%  & -381 & +2.52\%  & -441 \\ % & +0.28\% &	-209\\
           \hline
Maven      & VSM & -6.79\%  & +24 & +8.57\% & -113 & +6.78\%  & -287 & +0.52\%  & -74  \\ % & +0.02\% & -11\\
           & LSI & -0.51\%  & +2  & +7.12\% & -117 & +4.51\%  & -242 & +1.01\%  & -186  \\ %& +0.03\% & -21\\
           & JS  & +1.94\%  & -8  & +8.94\% & -127 & +7.39\%  & -351 & +1.68\%  & -231  \\ % & -0.21\% & +141\\
           \hline
Pig        & VSM & -30.50\% & +426 & -4.72\% & +319 & +0.85\% & -434 & +0.38\%  & -856 \\ % & -0.03\% & +198\\
           & LSI & -24.04\% & +410 & -1.53\% & +142 & +0.01\% & -4   & +0.21\%  & -511  \\ %& +0.01\% & -52\\
           & JS  & -11.70\% & +367 & +0.29\% & -55  & +0.09\% & -93  & +0.23\%  & -777  \\ %& -0.03\% & +217\\
           \hline
Infinispan & VSM & -5.12\%  & +309 & +0.85\% & -185 & +1.06\% & -677 & +0.66\%  & -1369 \\ %& +0.00\% & 0 \\
           & LSI & -4.85\%  & +309 & +1.76\% & -401 & +0.43\% & -301 & +0.32\%  & -697  \\ %& +0.00\% & +3\\
           & JS  & -4.32\%  & +264 & +1.42\% & -301 & +0.34\% & -273 & +0.27\%  & -634  \\ %& +0.01\% & -53\\
           \bottomrule
\end{tabular}
\end{table}

从表中可以看出当查全率小于20\%时，CLUSTER方法的准确率要比IR-ONLY低，这是因为CLUSTER方法是先让用户判断一些具有代表性的候选追踪线索，这些追踪线索未必是最可能有效的。相对于IR-ONLY算法本文方法刚开始会遇到更多的无效追踪线索。在查全率大于20\%时，CLUSTER方法前期的用户投入开始发挥作用，如表~\ref{T:fp-reduce}所示在查全率为60\%时，CLUSTER方法的准确度优于IR-ONLY，在iTrust-LSI下与IR-ONLY相比，CLUSTER方法的准确率提升了21.64\%。从表中可以得出用户在建立153 个正确追踪线索的过程中，CLUSTER 方法检索出的无效追踪线索比UD-CSTI 少349 个。当查全率在50\% 和80\% 之间时，CLUSTER 方法相对于IR-ONLY 的优势尤为明显。

根据实验结果，我们还有一点额外的观察。（1）对于同一个实验系统在不同的IR模型下，CLUSTER方法的表现差异很大。这是因为CLUSTER 方法主要是通过给追踪线索奖励来实现重排序，如前所述（公式）奖励值依赖于IR值，不同的IR模型对于IR值的计算有不同的方式。
（2）我们尝试过要求用户判断所有代码域与给定需求相关性，该做法对pig和Maven两个实验系统的性能提升不大。这可能是因为这两个系统的需求粒度太小。表~\ref{expirement_system_information}也验证了这一点，iTrust一个需求平均由8个类完成，而Maven和Pig的一个需求分别平均由4，5个类完成。在将来的工作中，我们计划用文本聚类的方法~\cite{Palomba2017Recommending}增大需求粒度。

\section{本章小结}
在本章中，我们通过对开源软件在issue-tracking工具上的行为信息进行分析整理，组织了其需求到代码的追踪关系。此外，我们通过运行开源系统自带的用于验证系统功能的测试用例得到了我们方法所需的代码依赖。最终，我们用一个被领域内广泛用于可追踪方法验证的高质量数据集和三个被广泛应用于日常实践的开源系统验证了我们方法的有效性和实用性。


\begin{comment}
\begin{table}[htbp]
  \centering
  \caption{软件功能及所用构建工具}
  \label{T:SoftwareInfo}
  \begin{tabular}{@{}lll@{}}
  \toprule
  系统        & 功能     & 构建工具     \\ \midrule
  Infinispan  & 数据库   & Maven        \\
  Maven       & 构建工具 & Maven        \\
  Pig         & 编译器   & Ant          \\ \bottomrule
  \end{tabular}
\end{table}
在~\ref{expirement_system_information}中已经提到，Pig、Infinispan和Maven均是我们通过对~\cite{Rath2017IlmSeven}提供的数据进行分析整理得出的数据集，~\cite{Rath2017IlmSeven}收集了这三个实验系统的Jira数据和git 数据，Jira是Atlassian公司出品的项目与事务追踪工具，被广泛用于缺陷定义、客户服务、需求收集、流程审批、任务跟踪和敏捷管理等领域。图~\ref{F:issue_pig_4963}

issue表中是各种issue集合，包括Bug、任务（Task）、需求（New Feature）等信息。我们主要使用New Feature 类型的issue，这种类型的issue是对一个新功能的描述~\cite{Heck2013trackers,Shi2017linguistic}。通过观察知其description字段是对这个issue的描述，我们把它看成是一个需求文本。表~change\_set和~change\_set\_link描述与issue对应的代码提交，而code\_change 描述的是一次代码提交引起的代码变更。因此通过~issue、~change\_set、~change\_set\_link和~code\_change我们就可以得到从需求issue到代码变更~code\_change的追踪关系。此外，~issue\_link 描述的是需求issue之间的关系，包括重复、从属、依赖等关系。我们对于存在特定关系的issue进行合并，最终得到需求issue到代码变更所在类的追踪关系。issue筛选规则如下：
\begin{enumerate}
  \item 忽略带有关键词testing或者testcase的issue，因为这些issue往往是和测试集有关系，不是软件系统的功能性需求。
  \item issue必须已经被完成并且有与之关联的code\_change，只有这样我们才能生成需求（issue）到代码的追踪关系。
  \item 我们只选择优先级为Major和Critical的issue，因为我们认为这种issue是功能性需求的概率更大。
  \item 我们只选择类型为New Feature（或Feature Request）的issue，我们认为这种需求粒度比较解决传统的需求（例如iTrust的需求），类型为Bug的issue往往粒度太小，类型为Task的issue又往往粒度太大。
\end{enumerate}
此外，当issue之间的关系为从属（part-of）、重复（duplicate）、替代（supersede）时，我们会将几个issue进行合并。按上述方法我们通过整理得到了 Maven、Pig和Infinispan的RTM数据集。
%需要说明的是，可能会存在这样一种情况：为了完成需求C，源代码里增加了类Func ，在类Func里与用到了Origin类，但是Origin 类并未发生代码变更。此时我们的方法只能得出需求C和代码Func存在追踪关系，然而需求C和代码元素Origin也是可能存在代码依赖的。
实验结果显示我们构造的数据集具有较高的文本质量（参见~\ref{sec:result_and_discussion}实验数据分析），能够有效的评估我们方法的正确性。
\end{comment}

